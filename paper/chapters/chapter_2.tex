\section{Related Work}
\label{sec_relatedwork}

Much research has been done recently in image clustering and semantic clustering, with application areas in image segmentation, compact representation of large image sets, search space reduction and avoiding the semantic gap in content based image retrieval \cite{Lim2011}. \\
However, most of these works present new algorithms for one of the above use cases, not methods to retrieve training data. \\

Related Subjects: Image Annotation, semantic clustering, content-based image retrieval

\subsection{Semantic Clustering and Tags}
The idea of clustering search results based on tags and other annotations has been implemented before by \cite{Ramage2009} but for web pages instead of images. The main difference is that documents such as web pages consist of words, so their content itself can be used for semantic analysis.
Current issues with tag-based search and clustering are mostly related to the lack of a defined tag vocabulary (e.g. the use of synonyms, homonyms, variations in spelling etc.), and elaborated on more closely in \cite{Auer2011}.

\subsection{Image Annotation and Content-Based Image Retrieval}
%% ?? http://ganges.usc.edu/pgroupW/images/6/6b/Cvm2012.pdf: detect objects and organize images based on the relations of the objects within.
%% http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=718510: review of visual features for cbir

Ideas exist to use visual features to semantically analyze and classify images. \cite{Liu2007} and \cite{Zhang2012} provide good summaries and evaluations of the different approaches how this could be done. Both conclude that this so-called \emph{Automatic Image Annotation} \index{Automatic Image Annotation} is computation-intensive and not yet fully mature.

%% http://infolab.stanford.edu/~wangz/project/imsearch/review/MTA/neela.pdf: summary of semantic image interpretation; Overview of foundations 

One approach that combines semantics and visuals is \cite{Lindstaedt2009}, which tries to annotate images (with a defined vocabulary??) based on visual features and existing tags, so-called \emph{folksonomies}. Their goal, however, is to create additional annotations for not or poorly tagged images.