%
\section{Evaluation}
\label{sec_literatur}

\subsection{Method}
Picture annotation tool, 200 pictures \\
compare two pictures: for each, does it display food? semantically not similar / same object / same object and same context? visually similar / not similar? \\

receive testset from users \\

how are quality measures calculated? \\

search food: precision  / recall of picture inclusion (compare synset detection mechanisms?) \\
evaluate tree nodes based on same object annotations \\
evaluate mcl clusters based on same object and on same context annotations (compare both, what does mcl actually do?) \\

evaluate visuals with large minimal node size \\

vary parameters given by frontend \\

\subsection{Results}
